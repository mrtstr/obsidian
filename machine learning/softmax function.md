### softmax function
- the [[softmax function]] $\mathrm{SOFTMAX}: \mathrm{R}^n \to [0,1]^{n}$ turns the input into a [[probability mass function (PMF)]]
	→ normalized positive output of the same dimensions

$$
\begin{split}
\mathrm{SOFTMAX}(Z) = \frac{1}{\sum_{i=1}^n \exp(y_i)} \exp(X)
\end{split}
$$
- used as output function in [[classification]] problems for example with [[neural network]] and [[multinomial logistic regresssion]]

# anki

START
Basic
[[softmax function]]
- definition
- application
Back: 
### softmax function
- the [[softmax function]] $\mathrm{SOFTMAX}: \mathrm{R}^n \to [0,1]^{n}$ turns the input into a [[probability mass function (PMF)]]
	→ normalized positive output of the same dimensions

$$
\begin{split}
\mathrm{SOFTMAX}(Z) = \frac{1}{\sum_{i=1}^n \exp(y_i)} \exp(X)
\end{split}
$$
- used as output function in [[classification]] problems for example with [[mathematics/stochastics/statistical learning/models/neural networks/neural networks]] and [[multinomial logistic regresssion]]

Tags: mathematics SS25
<!--ID: 1752949761743-->
END