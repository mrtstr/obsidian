# Lebenslauf

## Wiing studium
- Thermodynamik, mechanik, regelungstechnik
- Abschlussarbeit:
	- automatische verarbeitung von nano indenter daten zur chrakterisierung der mechanischen eigenschaften von betterie annoden.
	→ untersuchen der eigenschaften von  binder 
- verarbeitung zeitreihen von sensordaten

## Informatik mit Mathe Nebenfach
- fokus Mathe grundlagen (statistik, optimierung, numerik) und machine learning
- Abschlussarbeit: Domain adaption im autonomen Fahren
- deep learning mode zur objekterkennung
- adaption auf wechselnde bedingungen

## New Yorker als data scientist ab 2021
- Arbeit mit python samt data science stack
	- numpy, pandas, sklearn
	- pytorch fuer deep learning
	- pyspark/pyarrow fuer verarbeitung von grossen datenmengen
- technisch
	- ETL Pipelines: pyspark im hadoop cluster
	- In memory datenmenagement: distributed - in memory mit pyarrow 
	- CI/CD mit Jenkins und GitHub
	- Deployment der modelle in Kubernetes
- Bau von system zur Nachfrage vorhersage (items auf store level)
	- model zur vorhersage von nachfrage quantilen 
	- proof of concept → prototype → production system
		1) proof concept
			- untersuchen des business impacts auf basis von nachfrage in der vergangenheit
			- ganzzahlige optimierung - was waere optimale warenverteilung
			- Monte Carlo simulation von business processen 
		2) protype fuer vorhersagemodell
			- test verschiedener modelle und daten
		3) production system
			- piepeline tur automatischen daten vorbereitung
			- model deployment in kubernetes
			- Unterschiedliche Daten arten:
				- sowohl structured→ Tabellen mit Kategorischen Features
				- unstrukturierte Daten → (Bild Vektoren)

# Fragen
- use case
- techstack: spark cloud...?
- Art der daten (visuel, lidar...)
- projekt management
- team groesse und organisation
- in welcher phase (zeitplan bis production)