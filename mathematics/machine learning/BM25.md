### BM25
- classical ranking function from information retrieval
- based on **explicit word occurrence** (exact word overlap)
- used for sparse retrieval in [[retrieval augmented generation]]

$$
\mathrm{score(q, d)} = \sum_{t \in q} \mathrm{IDF}(t) \cdot \frac{\mathrm{TF(t, d)}}{\mathrm{TF(t, d)}+\mathrm{normalization}(d)}
$$

- $\mathrm{IDF}(t)$: how rare is the term $t$ across the document collection
- $\mathrm{TF(t, d)}$: how often does term $t$ appear in the document $d$
- $\mathrm{normalization}(d)$: based on the length of document $d$ → ensures that long and short documents are treated fairly

#### criteria
- rare words have a higher weight
- long and short documents are treated fairly
- diminishing returns: first occurrences have a high impact but the followings less and less

# anki

START
Basic
[[BM25]]
- concept
- equation with meaning
- ranking criteria
- where is it used

Back: 
### BM25
- classical ranking function from information retrieval
- based on **explicit word occurrence** (exact word overlap)
- used for sparse retrieval in [[retrieval augmented generation]]

$$
\mathrm{score(q, d)} = \sum_{t \in q} \mathrm{IDF}(t) \cdot \frac{\mathrm{TF(t, d)}}{\mathrm{TF(t, d)}+\mathrm{normalization}(d)}
$$

- $\mathrm{IDF}(t)$: how rare is the term $t$ across the document collection
- $\mathrm{TF(t, d)}$: how often does term $t$ appear in the document $d$
- $\mathrm{normalization}(d)$: based on the length of document $d$ → ensures that long and short documents are treated fairly

#### criteria
- rare words have a higher weight
- long and short documents are treated fairly
- diminishing returns: first occurrences have a high impact but the followings less and less


Tags: ml WS2526
<!--ID: 1768229318735-->
END
